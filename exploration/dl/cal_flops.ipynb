{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafaa235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calflops import calculate_flops\n",
    "from torchvision import models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6cdfd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  61.1 M  \n",
      "fwd MACs:                                                               714.188 MMACs\n",
      "fwd FLOPs:                                                              1.4297 GFLOPS\n",
      "fwd+bwd MACs:                                                           2.1426 GMACs\n",
      "fwd+bwd FLOPs:                                                          4.2892 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "AlexNet(\n",
      "  61.1 M = 100% Params, 714.19 MMACs = 100% MACs, 1.43 GFLOPS = 100% FLOPs\n",
      "  (features): Sequential(\n",
      "    2.47 M = 4.042% Params, 655.57 MMACs = 91.7918% MACs, 1.31 GFLOPS = 91.7984% FLOPs\n",
      "    (0): Conv2d(23.3 K = 0.0381% Params, 70.28 MMACs = 9.8401% MACs, 140.75 MFLOPS = 9.8442% FLOPs, 3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 193.6 KFLOPS = 0.0135% FLOPs, inplace=True)\n",
      "    (2): MaxPool2d(0 = 0% Params, 0 MACs = 0% MACs, 193.6 KFLOPS = 0.0135% FLOPs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(307.39 K = 0.5031% Params, 223.95 MMACs = 31.3571% MACs, 448.04 MFLOPS = 31.337% FLOPs, 64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 139.97 KFLOPS = 0.0098% FLOPs, inplace=True)\n",
      "    (5): MaxPool2d(0 = 0% Params, 0 MACs = 0% MACs, 139.97 KFLOPS = 0.0098% FLOPs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(663.94 K = 1.0866% Params, 112.14 MMACs = 15.7018% MACs, 224.35 MFLOPS = 15.6913% FLOPs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 64.9 KFLOPS = 0.0045% FLOPs, inplace=True)\n",
      "    (8): Conv2d(884.99 K = 1.4484% Params, 149.52 MMACs = 20.9357% MACs, 299.08 MFLOPS = 20.9188% FLOPs, 384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 43.26 KFLOPS = 0.003% FLOPs, inplace=True)\n",
      "    (10): Conv2d(590.08 K = 0.9657% Params, 99.68 MMACs = 13.9571% MACs, 199.4 MFLOPS = 13.9468% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 43.26 KFLOPS = 0.003% FLOPs, inplace=True)\n",
      "    (12): MaxPool2d(0 = 0% Params, 0 MACs = 0% MACs, 43.26 KFLOPS = 0.003% FLOPs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 9.22 KFLOPS = 0.0006% FLOPs, output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    58.63 M = 95.958% Params, 58.62 MMACs = 8.2082% MACs, 117.25 MFLOPS = 8.2009% FLOPs\n",
      "    (0): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.5, inplace=False)\n",
      "    (1): Linear(37.75 M = 61.7877% Params, 37.75 MMACs = 5.2855% MACs, 75.5 MFLOPS = 5.2805% FLOPs, in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 4.1 KFLOPS = 0.0003% FLOPs, inplace=True)\n",
      "    (3): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.5, inplace=False)\n",
      "    (4): Linear(16.78 M = 27.4649% Params, 16.78 MMACs = 2.3491% MACs, 33.55 MFLOPS = 2.3469% FLOPs, in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 4.1 KFLOPS = 0.0003% FLOPs, inplace=True)\n",
      "    (6): Linear(4.1 M = 6.7053% Params, 4.1 MMACs = 0.5735% MACs, 8.19 MFLOPS = 0.573% FLOPs, in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Alexnet FLOPs:1.4297 GFLOPS   MACs:714.188 MMACs   Params:61.1008 M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.alexnet()\n",
    "batch_size = 1\n",
    "input_shape = (batch_size, 3, 224, 224)\n",
    "flops, macs, params = calculate_flops(model=model, \n",
    "                                      input_shape=input_shape,\n",
    "                                      output_as_string=True,\n",
    "                                      output_precision=4)\n",
    "print(\"Alexnet FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))\n",
    "#Alexnet FLOPs:4.2892 GFLOPS   MACs:2.1426 GMACs   Params:61.1008 M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361f769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
