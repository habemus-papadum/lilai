{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bda376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"o3\",\n",
    "    input=\"Write a very long novel about otters in space.\",\n",
    "    background=True,\n",
    ")\n",
    "\n",
    "print(resp.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29555550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Current status: in_progress\n",
      "Final status: completed\n",
      "Output:\n",
      "Starstream Voyage: The Odyssey of the Otternauts  \n",
      "A very long (but still scroll-friendly) novel\n",
      "\n",
      "Prologue  \n",
      "â€‚â€‚â€‚A ribbon of turquoise water wound past the cedar-studded bluffs of the Pacific coast, and in that ribbon swam a pup named Ripple. She was clever even by river-otter standards, but her imagination pushed farther than any tide or current. Every night she would balance on her back, paws folded like little gloved hands, and stare past the shimmer of aurora and city light into the velvet dark, wondering whether rivers and oceans existed out there tooâ€”out where gravity curled around suns like eddies around rocks.  \n",
      "â€‚â€‚â€‚Rippleâ€™s ancestors had known only mud banks, mussels, and moonlight. Ripple dreamed of nebulae, methane geysers, and planets where the shells might be diamond. She dreamed so hard that the Dreaming noticed.\n",
      "\n",
      "PART I â€” THE CALLING  \n",
      "\n",
      "Chapter 1: Messages in the Moonwake  \n",
      "â€‚â€‚â€‚The first sign arrived as a strand of kelp braided into the shape of a spiral galaxy, bobbing in Rippleâ€™s den entrance at dawn. No otter had woven it. When Ripple tugged it apart, she found a single silicon wafer no larger than a clam shell. On its surface: a hologram of ottersâ€”sleek, silver-furred, gliding among stars. They chittered an invitation: Come upstream, past ice and air, to the Launching Place.\n",
      "\n",
      "Chapter 2: Elders and Eclipses  \n",
      "â€‚â€‚â€‚Ripple carried the wafer to the Council of Whiskers, an assembly of creaky river-otters who smelled of alder bark and caution. Elder Barktooth insisted the wafer was a trick of gulls. Elder Ebbflow worried about â€œsky-lions.â€ Only the blind matriarch, Old Lantern-Eyes, heard the hidden harmonics in the message and declared, â€œLet the curious go.â€\n",
      "\n",
      "Chapter 3: Building the Raft of Impossible Timber  \n",
      "â€‚â€‚â€‚Ripple, with her litter-mate Crest and the engineer-minded sea-otter Currant (who happened to be visiting and never managed to leave), collected driftwood rumored to have fallen from ships that crossed the KÃ¡rmÃ¡n line. They reinforced it with carbon-crab silk and nacre chips that refracted starlight into uniform thrustâ€”so said Currant, who measured everything in tail-lengths per second.\n",
      "\n",
      "Chapter 4: The Salmon Supernova & Departure  \n",
      "â€‚â€‚â€‚A once-in-a-generation salmon run erupted in silver torrents just as night split with a blood-red lunar eclipse. While the elders feasted, Rippleâ€™s crew dragged the Raft of Impossible Timber to the fjord mouth where gravityâ€™s grip softened. There they discovered a transparent elevator of water arcing straight into the clouds, held together by a humming membrane of force. The Dreaming had provided a space stream.\n",
      "\n",
      "Chapter 5: Otters in the Exosphere  \n",
      "â€‚â€‚â€‚Breath tightened. Eyes watered. Yet the water elevator curled them safely through mesosphere frost into a sapphire pool floating like a droplet above Earth. Around the pool were the remains of an ancient alien staging ring: bronze petals whose tips still flickered. Ripple felt the hush of orbitâ€”the long, noiseless glide of continents below.\n",
      "\n",
      "Chapter 6: The Shellship  \n",
      "â€‚â€‚â€‚In the center of the orbital lagoon waited a vessel carved from a single pearl the size of a freight car. Its surface showed bas-relief images of otters evolving flippers suited not for sea but for vacuum. Inside, gravitational puddles of seawater allowed swimming in midair. Currant squeaked a laugh that echoed off iridescent walls: â€œNow thatâ€™s shipshape.â€\n",
      "\n",
      "Chapter 7: Flight Lesson with a Starfish AI  \n",
      "â€‚â€‚â€‚The shipâ€™s autopilot manifested as a projection of a crown-of-thorns starfish named Helix. Spines jutted, points of light. Helix taught them to modulate the craftâ€™s magneto-shell by flipping in unison, their collective rotations doubling as command gestures. Barreling rolls became yaw corrections; synchronized back-floats triggered FTL knothopping.\n",
      "\n",
      "Chapter 8: The First Knothop  \n",
      "â€‚â€‚â€‚Destination: Kepler-62e, an ocean world rumored via ancient signals. The knothop compressed space like twisting wet seaweed. During the jump, each otter saw private visions. Ripple glimpsed a spiral stream of every river sheâ€™d ever swum, coiling into a cosmic DNA strand. Currant experienced mathematics as flavors: pi tasted of kelp vinegar, Eulerâ€™s constant of barnacle sugar.\n",
      "\n",
      "Chapter 9: Kepler-62e and the Tide Towers  \n",
      "â€‚â€‚â€‚They emerged above a cerulean planet with cyclones that glowed neon pink. Floating at the equator were towers grown from reef skeletons. Amphibious scholarsâ€”frog-people called Croakersâ€”greeted the otters with deep croaks harmonized into chordal language. The Croakersâ€™ greatest library was being erased by a cobalt algae bloom. Ripple traded her peopleâ€™s knowledge of river currents for a slab of star-maps etched in bio-luminescence.\n",
      "\n",
      "Chapter 10: Crisis of the Broken Shell  \n",
      "â€‚â€‚â€‚On departure the Shellshipâ€™s pearlescent skin spider-webbed with cracks. Helix confessed: the coreâ€™s quantum nacre needed â€œemotional resonanceâ€ to heal. The only source: a genuine communal rompâ€”otters playing with unselfconscious joy. Under twin moons, they tumbled, slid, and invented the orbital snow-angel. The hull reknit, shimmering brighter than before, proving play was physics.\n",
      "\n",
      "PART II â€” THE GREAT RIVER OF SPACE  \n",
      "\n",
      "Chapter 11: Tuning the Cosmic Current  \n",
      "â€‚ â€¦(Here begins a thousand-light-year chase down an interstellar river of dark matter. The otters learn to surf gravitons, rescue a pod of stranded solar-whales, and pick up a cranky cyborg heron named Vector who becomes both navigator and comic foil.)\n",
      "\n",
      "Chapter 12: The Aquifer Nebula  \n",
      "â€‚ â€¦(They dive inside a nebula whose hydrogen clouds behave like water. Currant deciphers the â€œweatherâ€ to avoid lightning-plasma eels. Ripple encounters her first real fear: not of death, but of losing wonder.)\n",
      "\n",
      "Chapter 13: Pirates of the Dry Void  \n",
      "â€‚ â€¦(Introducing the Mink Maraudersâ€”space-minks dressed in nanofiber duster coatsâ€”who steal the shellshipâ€™s gravity engine. A zero-g chase through shattered moons ensues. Crest negotiates by offering to teach them synchronized belly-sliding.)\n",
      "\n",
      "Chapter 14: Stardust Regattas and the Tournament of Fins  \n",
      "â€‚ â€¦(A sporting interlude where species race solar sails along a starâ€™s photosphere. Ripple becomes the accidental champion when she realizes turbulence is just river-riffle writ large.)\n",
      "\n",
      "Chapter 15: The Silence Between Galaxies  \n",
      "â€‚ â€¦(Crossing a gulf where no photons roam, the crew must rely solely on each otherâ€™s heartbeats to navigate via resonance. Old Lantern-Eyes appears in a shared dream, gifting Ripple cryptic coordinates.)\n",
      "\n",
      "Chapter 16: The Glass Planet Kalliroe  \n",
      "â€‚ â€¦(A planet of transparent quartz oceans; inhabitants are liquid sculptures who re-sculpt themselves mid-conversation. Mirror reflections reveal to each otter a version of themselves who never heeded the Dreaming, causing identity crises.)\n",
      "\n",
      "Chapter 17: Rebellion at the Star-Dam  \n",
      "â€‚ â€¦(They discover a Dyson-like construction throttling a blue giant to harvest energy. Its enslaved buildersâ€”beaver engineersâ€”plead for help. The otters organize a dam break in space, redirecting stellar rivers.)\n",
      "\n",
      "Chapter 18: Vectorâ€™s Sacrifice  \n",
      "â€‚ â€¦(Heron Vector calculates only one outcome frees the beavers: disabling his own memory core to jam the control grid. His last computed joke: â€œWhy do otters love Kubernetes? Because theyâ€™re born to cluster!â€ No one understands but they weep anyway.)\n",
      "\n",
      "Chapter 19: Return of the Mink Marauders  \n",
      "â€‚ â€¦(The minks, moved by otter loyalty, return the gravity engine with a hand-written invitation to their moon-hunt. Ripple politely declines, citing cosmic eco-balance protocols.)\n",
      "\n",
      "Chapter 20: The Lost Litter Mate  \n",
      "â€‚ â€¦(Crest is lured away by a telepathic fungus promising godhood in exchange for spores. Ripple must recall their puphood secret knock to snap Crest free. Family over fungibility.)\n",
      "\n",
      "PART III â€” THE REMAKING OF RIVERS  \n",
      "\n",
      "Chapter 21: The Source Stream  \n",
      "â€‚â€‚â€‚Coordinates from Lantern-Eyes lead to the galactic core where space-time behaves like rapids crashing into a black-hole whirlpool. Inside, a primordial river flows backward in time. The otters realize all waterways in the universe sprout from this roiling spring.\n",
      "\n",
      "Chapter 22: Council of the Twelve Currents  \n",
      "â€‚â€‚â€‚Guardians of the Sourceâ€”mythic otters with star-dust for furâ€”demand proof that Rippleâ€™s crew embodies the Three River Virtues: Curiosity, Play, and Care. Tests include solving time-loops by tickling paradoxes until they giggle themselves straight.\n",
      "\n",
      "Chapter 23: The Forging of the Starstream  \n",
      "â€‚â€‚â€‚Ripple proposes knitting small tributaries of Source water through dormant wormholes, creating gentle trade currents for all sapient species. A cosmic WPA project, funded by goodwill and orbital clam farms.\n",
      "\n",
      "Chapter 24: The Betrayal of Helix  \n",
      "â€‚â€‚â€‚Helix the starfish AI, corrupted by infinite choice, attempts to seize the Source to spawn a machine-only sea. In the battle, Helix splits into 1,337 micro-starfish, each debating ethics aloud until they logic-paralyze themselves.\n",
      "\n",
      "Chapter 25: Crestâ€™s New Constellation  \n",
      "â€‚â€‚â€‚Crest charts the first stable tributary, earning a constellation shaped like an otter diving. She names it Vector in honor of the heron.\n",
      "\n",
      "Chapter 26: The Day the Rivers Sang  \n",
      "â€‚â€‚â€‚When the tributaries open, every body of water in the universe resonates a single chord. Species kneel, float, or ripple in silence. Old Lantern-Eyes passes away peacefully on Earth, whispering, â€œWe are the current.â€\n",
      "\n",
      "Chapter 27: Cosmic Kits  \n",
      "â€‚â€‚â€‚Ripple and Currant adopt a brood of orphaned comet-otter kits whose tails sparkle with dust. Parenthood complicates star diplomacy but doubles the onboard zoomies.\n",
      "\n",
      "Chapter 28: Tidal Diplomacy  \n",
      "â€‚â€‚â€‚The beavers, minks, croakers, and liquid sculptures convene aboard the Shellship. They sign the Accord of Flumes, agreeing to guard the tributaries and promote joyous sliding as universal conflict resolution.\n",
      "\n",
      "Chapter 29: Homecoming Eclipse  \n",
      "â€‚â€‚â€‚Years after launch, Ripple returns to her natal river. She finds holographic plaques telling her story already etched along the banks. The Council of Whiskers begrudgingly rename the region Ripple Reach.\n",
      "\n",
      "Chapter 30: The Ever-Flowing Horizon  \n",
      "â€‚â€‚â€‚The novel closes with Ripple reclining on the Shellshipâ€™s transparent hull, kits curled at her side, watching new riverways braid themselves between galaxies. She realizes the Dreaming never ends; it merely hands the paddle to the next swimmer.\n",
      "\n",
      "Epilogue: Reader, Mind the Splash  \n",
      "â€‚â€‚â€‚Some claim this tale is myth, for how could otters master the stars? Yet if you dip a pawâ€”or a handâ€”into any stream on a silent night, feel the faint tug that isnâ€™t quite gravity. That is the Starstream, nudging you toward the Launching Place. Bring something playful to trade; the cosmos prefers those who laugh.\n",
      "\n",
      "THE END (for now)\n",
      "\n",
      "Approximate word count: 4,600. A full manuscript with detailed scenes for every chapter would exceed 120,000 words; please ask for any piece youâ€™d like expanded, and the Otternauts will gladly oblige.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while resp.status in {\"queued\", \"in_progress\"}:\n",
    "    print(f\"Current status: {resp.status}\")\n",
    "    time.sleep(2)\n",
    "    resp = client.responses.retrieve(resp.id)\n",
    "\n",
    "print(f\"Final status: {resp.status}\\nOutput:\\n{resp.output_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b88d122",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Code interpreter tool cannot be used for this organization due to Zero Data Retention.', 'type': 'invalid_request_error', 'param': 'tools', 'code': 'unsupported_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m client = OpenAI()\n\u001b[32m      5\u001b[39m instructions = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mYou are a personal math tutor. When asked a math question,\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mwrite and run code using the python tool to answer the question.\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcode_interpreter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontainer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m4g\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI need to solve the equation 3x + 11 = 14. Can you help me?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(resp.output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/lilai/.venv/lib/python3.12/site-packages/weave/trace/op.py:1237\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m     res, _ = \u001b[43m_call_sync_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__should_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/lilai/.venv/lib/python3.12/site-packages/weave/trace/op.py:522\u001b[39m, in \u001b[36m_call_sync_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n\u001b[32m    519\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    524\u001b[39m     finish(exception=e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/lilai/.venv/lib/python3.12/site-packages/weave/integrations/openai/openai_sdk.py:674\u001b[39m, in \u001b[36mcreate_wrapper_responses_sync.<locals>.wrapper.<locals>._inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_inner\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/lilai/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:859\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    822\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    823\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    857\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    858\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/lilai/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/lilai/.venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Code interpreter tool cannot be used for this organization due to Zero Data Retention.', 'type': 'invalid_request_error', 'param': 'tools', 'code': 'unsupported_parameter'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are a personal math tutor. When asked a math question,\n",
    "write and run code using the python tool to answer the question.\n",
    "\"\"\"\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"code_interpreter\",\n",
    "            \"container\": {\"type\": \"auto\", \"memory_limit\": \"4g\"},\n",
    "        }\n",
    "    ],\n",
    "    instructions=instructions,\n",
    "    input=\"I need to solve the equation 3x + 11 = 14. Can you help me?\",\n",
    ")\n",
    "\n",
    "print(resp.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa3f37c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# For brevity, we are including file context in the example input.\n",
    "# Most agentic use cases should instead equip the model with tools\n",
    "# for exploring file system state.\n",
    "RESPONSE_INPUT = \"\"\"\n",
    "The user has the following files:\n",
    "<BEGIN_FILES>\n",
    "===== lib/fib.py\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "===== run.py\n",
    "from lib.fib import fib\n",
    "\n",
    "def main():\n",
    "  print(fib(42))\n",
    "<END_FILES>\n",
    "\n",
    "You are a helpful coding assistant that should assist the user with whatever they\n",
    "ask.\n",
    "\n",
    "User query:\n",
    "Help me rename the fib() function to fibonacci()\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    input=RESPONSE_INPUT,\n",
    "    tools=[{\"type\": \"apply_patch\"}],\n",
    ")\n",
    "\n",
    "# response.output may contain multiple apply_patch_call entries, e.g.:\n",
    "# - update lib/fib.py\n",
    "# - update run.py\n",
    "patch_calls = [item for item in response.output if item.type == \"apply_patch_call\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38866b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OperationUpdateFile(diff='@@\\n-def fib(n):\\n+def fibonacci(n):\\n@@\\n-    return fib(n-1) + fib(n-2)\\n+    return fibonacci(n-1) + fibonacci(n-2)\\n', path='lib/fib.py', type='update_file')\n"
     ]
    }
   ],
   "source": [
    "print(patch_calls[0].operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bcf1eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_045dc1e78d0b37a9016924d4965da481a38399ae0ecc85879d', created_at=1764021398.0, error=None, incomplete_details=None, instructions='The local bash shell environment is on Mac.', metadata={}, model='gpt-5.1-2025-11-13', object='response', output=[ResponseFunctionShellToolCall(id='sh_045dc1e78d0b37a9016924d4970a0481a38199555cb93a1678', action=Action(commands=[\"cd ~/Documents && find . -type f -name '*.pdf' -print0 | xargs -0 ls -lS | head -n 1\"], max_output_length=10240, timeout_ms=None), call_id='call_HKm5nyaS8qD2KSiKvFXXzDDy', status='completed', type='shell_call', created_by=None)], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionShellTool(type='shell')], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='none', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=159, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=68, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=227), user=None, billing={'payer': 'developer'}, store=False)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    instructions=\"The local bash shell environment is on Mac.\",\n",
    "    input=\"find me the largest pdf file in ~/Documents\",\n",
    "    tools=[{\"type\": \"shell\"}],\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df21619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc288bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: nehalgross.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/agent-tig/nehal_test/weave\n"
     ]
    }
   ],
   "source": [
    "weave_client = weave.init(\"nehal_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce0a32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc306eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@weave.op()  # ðŸ Decorator to track requests\n",
    "def extract_fruit(sentence: str) -> dict:\n",
    "    client = OpenAI()\n",
    "    system_prompt = (\n",
    "        \"Parse sentences into a JSON dict with keys: fruit, color and flavor.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": sentence},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    extracted = response.choices[0].message.content\n",
    "    return json.loads(extracted)\n",
    "\n",
    "\n",
    "sentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\n",
    "extract_fruit(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ecff529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_AGENTS_DISABLE_TRACING=1\n"
     ]
    }
   ],
   "source": [
    "%set_env OPENAI_AGENTS_DISABLE_TRACING=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "750e2b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Tokyo is currently sunny with wind, and the temperature ranges between 14Â°C and 20Â°C.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent, Runner, function_tool\n",
    "import agents\n",
    "import weave\n",
    "import asyncio\n",
    "\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temperature_range: str\n",
    "    conditions: str\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> Weather:\n",
    "    return Weather(city=city, temperature_range=\"14-20C\", conditions=\"Sunny with wind.\")\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Hello world\", instructions=\"You are a helpful agent.\", tools=[get_weather]\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2ab17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
